{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc221915",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa99fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a887632",
   "metadata": {},
   "outputs": [],
   "source": [
    "User_id = []\n",
    "Bus_id = []\n",
    "Star = []\n",
    "Useful = []\n",
    "Funny = []\n",
    "Cool = []\n",
    "Text = []\n",
    "I=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a33f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ndavidson/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ndavidson/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/ndavidson/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1091e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Final = pd.read_csv('./Downloads/Data_Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27775c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "X = DF_Final.Review\n",
    "stemmer = WordNetLemmatizer()\n",
    "for i in range(0, len(X)):\n",
    "    # Remove all the special characters, like parathesis\n",
    "    document = re.sub(r'\\W', ' ', str(X[i]))\n",
    "    # remove all single characters: like a, b, c, d\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b710a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=0.1, max_df=0.7, \n",
    "stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c8904c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n = open(\"./Downloads/negative-words.txt\", \"r\")\n",
    "Negative_words = f_n.readlines()\n",
    "f_p = open(\"./Downloads/positive-words.txt\", \"r\")\n",
    "Positive_words = f_p.readlines()\n",
    "Voca = [i.rstrip('\\n') for i in Positive_words] + [i.rstrip('\\n') for i in \n",
    "Negative_words]\n",
    "vectorizer = CountVectorizer(vocabulary=np.unique(Voca))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe9e3ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User_id</th>\n",
       "      <th>Bus_id</th>\n",
       "      <th>Star</th>\n",
       "      <th>Useful</th>\n",
       "      <th>Cool</th>\n",
       "      <th>Funny</th>\n",
       "      <th>Review</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Bus_Ave_Star</th>\n",
       "      <th>User_Review_count</th>\n",
       "      <th>User_Useful_count</th>\n",
       "      <th>User_Funny_count</th>\n",
       "      <th>User_Cool_count</th>\n",
       "      <th>Elite</th>\n",
       "      <th>User_Fans</th>\n",
       "      <th>Users_Ave_Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4hBhtCSgoxkrFgHa4YAD-w</td>\n",
       "      <td>bbEXAEFr4RYHLlZ-HFssTA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great burgers,fries and salad!  Burgers have a...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Goleta</td>\n",
       "      <td>4.0</td>\n",
       "      <td>922</td>\n",
       "      <td>1687</td>\n",
       "      <td>694</td>\n",
       "      <td>1070</td>\n",
       "      <td>2015,2016,2017,2018,2019,20,20,2021</td>\n",
       "      <td>51</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>JYYYKt6TdVA4ng9lLcXt_g</td>\n",
       "      <td>SZU9c8V2GuREDN5KgyHFJw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We were a bit weary about trying the Shellfish...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>4.0</td>\n",
       "      <td>338</td>\n",
       "      <td>800</td>\n",
       "      <td>144</td>\n",
       "      <td>353</td>\n",
       "      <td>2012,2013,2014,2015,2016,2017,2018,2019,20,20,...</td>\n",
       "      <td>30</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Uk3X2AypU8AqvcYEVf7s6Q</td>\n",
       "      <td>eL4lyE7LNoXEMvpcJ8WNVw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This was a tough one!   On the merits of the w...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>4.0</td>\n",
       "      <td>431</td>\n",
       "      <td>2126</td>\n",
       "      <td>1245</td>\n",
       "      <td>1476</td>\n",
       "      <td>2012,2013,2014,2015,2016,2017,2018,2019,20,20,...</td>\n",
       "      <td>76</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LcqNuhqaYt5ekKzaRirmIg</td>\n",
       "      <td>SZU9c8V2GuREDN5KgyHFJw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I love trying fresh seafood on piers, wharfs a...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>4.0</td>\n",
       "      <td>258</td>\n",
       "      <td>452</td>\n",
       "      <td>125</td>\n",
       "      <td>183</td>\n",
       "      <td>2015,2016,2017</td>\n",
       "      <td>37</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gasLVm0KRwrVhPGRcqATjw</td>\n",
       "      <td>CHh0ZFrQcsk4boOItr2Zuw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I stopped in because I was hungry for some sna...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Carpinteria</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1638</td>\n",
       "      <td>2658</td>\n",
       "      <td>933</td>\n",
       "      <td>2297</td>\n",
       "      <td>2014,2015,2016,2017,2018,2019,20,20,2021</td>\n",
       "      <td>105</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 User_id                  Bus_id  Star  Useful  \\\n",
       "0           0  4hBhtCSgoxkrFgHa4YAD-w  bbEXAEFr4RYHLlZ-HFssTA   5.0       0   \n",
       "1           1  JYYYKt6TdVA4ng9lLcXt_g  SZU9c8V2GuREDN5KgyHFJw   5.0       0   \n",
       "2           2  Uk3X2AypU8AqvcYEVf7s6Q  eL4lyE7LNoXEMvpcJ8WNVw   3.0       5   \n",
       "3           3  LcqNuhqaYt5ekKzaRirmIg  SZU9c8V2GuREDN5KgyHFJw   5.0       2   \n",
       "4           4  gasLVm0KRwrVhPGRcqATjw  CHh0ZFrQcsk4boOItr2Zuw   4.0       1   \n",
       "\n",
       "   Cool  Funny                                             Review State  \\\n",
       "0     0      0  Great burgers,fries and salad!  Burgers have a...    CA   \n",
       "1     0      0  We were a bit weary about trying the Shellfish...    CA   \n",
       "2     0      0  This was a tough one!   On the merits of the w...    CA   \n",
       "3     1      0  I love trying fresh seafood on piers, wharfs a...    CA   \n",
       "4     2      0  I stopped in because I was hungry for some sna...    CA   \n",
       "\n",
       "            City  Bus_Ave_Star  User_Review_count  User_Useful_count  \\\n",
       "0         Goleta           4.0                922               1687   \n",
       "1  Santa Barbara           4.0                338                800   \n",
       "2  Santa Barbara           4.0                431               2126   \n",
       "3  Santa Barbara           4.0                258                452   \n",
       "4    Carpinteria           3.0               1638               2658   \n",
       "\n",
       "   User_Funny_count  User_Cool_count  \\\n",
       "0               694             1070   \n",
       "1               144              353   \n",
       "2              1245             1476   \n",
       "3               125              183   \n",
       "4               933             2297   \n",
       "\n",
       "                                               Elite  User_Fans  \\\n",
       "0                2015,2016,2017,2018,2019,20,20,2021         51   \n",
       "1  2012,2013,2014,2015,2016,2017,2018,2019,20,20,...         30   \n",
       "2  2012,2013,2014,2015,2016,2017,2018,2019,20,20,...         76   \n",
       "3                                     2015,2016,2017         37   \n",
       "4           2014,2015,2016,2017,2018,2019,20,20,2021        105   \n",
       "\n",
       "   Users_Ave_Star  \n",
       "0            4.20  \n",
       "1            4.12  \n",
       "2            4.05  \n",
       "3            3.99  \n",
       "4            3.79  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2dddb0",
   "metadata": {},
   "source": [
    "# **Train a Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a7dba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43076, 6786)\n",
      "(5384, 6786)\n",
      "(5385, 6786)\n",
      "(43076,)\n",
      "(5384,)\n",
      "(5385,)\n",
      "(23285, 18)\n"
     ]
    }
   ],
   "source": [
    "#80-10-10 split of train test\n",
    "test = DF_Final[(DF_Final['Star'] == 1.0) | (DF_Final['Star'] == 5.0)]\n",
    "Y = DF_Final['Star']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_rem, Y_train, Y_rem = train_test_split(X, Y, train_size=0.8)\n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem, Y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_valid.shape)\n",
    "print(Y_test.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "71b19208",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unbound method BaseException.with_traceback() needs an argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m mnb\u001b[38;5;241m.\u001b[39mpredict(X_test)     \n\u001b[0;32m---> 11\u001b[0m grid_results\u001b[38;5;241m.\u001b[39mappend([testsize, randomstate, \u001b[43mmean_squared_error\u001b[49m(y_test, y_test_pred)])\n\u001b[1;32m     12\u001b[0m grid_frame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(grid_results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     grid_frame\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom State\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE of Test\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;167;43;01mException\u001b[39;49;00m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unbound method BaseException.with_traceback() needs an argument"
     ]
    }
   ],
   "source": [
    "test_size = np.linspace(0.1, 1, num=9, endpoint=False)\n",
    "random_state = np.arange(0, 43)\n",
    "grid_results= []\n",
    "for testsize in test_size:\n",
    "    for randomstate in random_state:\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=testsize, random_state=randomstate)\n",
    "            mnb = MultinomialNB()\n",
    "            mnb.fit(X_train, y_train)\n",
    "            y_test_pred = mnb.predict(X_test)     \n",
    "            grid_results.append([testsize, randomstate, mean_squared_error(y_test, y_test_pred)])\n",
    "            grid_frame = pd.DataFrame(grid_results)\n",
    "            grid_frame.rename(columns={0:'Test Size', 1:'Random State', 2:'MSE of Test'}, inplace=True)\n",
    "        except Exception:\n",
    "            print(Exception.with_traceback())\n",
    "            print('error')\n",
    "            continue\n",
    "min_test_mse = grid_frame[grid_frame['MSE of Test'] == grid_frame['MSE of Test'].min()]\n",
    "min_test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "77b9e3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0e2b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(X_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ba8504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 131  108   72   48   21]\n",
      " [  41  128  279  141   81]\n",
      " [  25   86  548  759  252]\n",
      " [  14   43  304 1947 1444]\n",
      " [  28   24   77 1059 3109]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      0.34      0.42       380\n",
      "         2.0       0.33      0.19      0.24       670\n",
      "         3.0       0.43      0.33      0.37      1670\n",
      "         4.0       0.49      0.52      0.51      3752\n",
      "         5.0       0.63      0.72      0.68      4297\n",
      "\n",
      "    accuracy                           0.54     10769\n",
      "   macro avg       0.49      0.42      0.44     10769\n",
      "weighted avg       0.53      0.54      0.53     10769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(Y_rem, preds))\n",
    "print('\\n')\n",
    "print(classification_report(Y_rem, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1ed3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
